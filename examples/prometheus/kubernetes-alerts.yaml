apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: kubernetes-resources
  namespace: monitoring
spec:
  groups:
  - name: kubernetes.resources
    interval: 30s
    rules:
    # OOM Kill alert - triggers heal8s
    - alert: KubePodOOMKilled
      expr: |
        sum by (namespace, pod, container) (
          rate(kube_pod_container_status_restarts_total[5m])
        ) > 0
        and
        sum by (namespace, pod, container) (
          kube_pod_container_status_last_terminated_reason{reason="OOMKilled"}
        ) == 1
      for: 1m
      labels:
        severity: critical
        alertname: KubePodOOMKilled
      annotations:
        summary: "Pod {{ $labels.namespace }}/{{ $labels.pod }} was OOMKilled"
        description: "Container {{ $labels.container }} in pod {{ $labels.namespace }}/{{ $labels.pod }} was killed due to OOM (Out of Memory)"
    
    # HPA maxed out - triggers heal8s scale up
    - alert: KubeHpaMaxedOut
      expr: |
        kube_horizontalpodautoscaler_status_current_replicas{job="kube-state-metrics"}
        /
        kube_horizontalpodautoscaler_spec_max_replicas{job="kube-state-metrics"}
        >= 0.95
      for: 15m
      labels:
        severity: warning
        alertname: KubeHpaMaxedOut
      annotations:
        summary: "HPA {{ $labels.namespace }}/{{ $labels.horizontalpodautoscaler }} has reached max replicas"
        description: "HPA {{ $labels.namespace }}/{{ $labels.horizontalpodautoscaler }} has been running at {{ $value | humanizePercentage }} of max replicas for 15 minutes"
    
    # Pod crash looping - triggers heal8s rollback
    - alert: KubePodCrashLooping
      expr: |
        rate(kube_pod_container_status_restarts_total[15m]) > 0
      for: 5m
      labels:
        severity: critical
        alertname: KubePodCrashLooping
      annotations:
        summary: "Pod {{ $labels.namespace }}/{{ $labels.pod }} is crash looping"
        description: "Container {{ $labels.container }} in pod {{ $labels.namespace }}/{{ $labels.pod }} is restarting {{ $value | humanize }} times / second"
    
    # Container memory near limit - preventive alert
    - alert: ContainerMemoryNearLimit
      expr: |
        container_memory_working_set_bytes{container!=""} 
        / 
        container_spec_memory_limit_bytes{container!=""} > 0.85
      for: 10m
      labels:
        severity: warning
        alertname: ContainerMemoryNearLimit
      annotations:
        summary: "Container memory usage is high"
        description: "Container {{ $labels.container }} in pod {{ $labels.namespace }}/{{ $labels.pod }} is using {{ $value | humanizePercentage }} of memory limit"
    
    # Container CPU throttling
    - alert: ContainerCPUThrottling
      expr: |
        rate(container_cpu_cfs_throttled_seconds_total{container!=""}[5m]) > 0.5
      for: 10m
      labels:
        severity: warning
        alertname: ContainerCPUThrottling
      annotations:
        summary: "Container is being throttled"
        description: "Container {{ $labels.container }} in pod {{ $labels.namespace }}/{{ $labels.pod }} is being CPU throttled {{ $value | humanize }} seconds/second"
